# Unisimon Portal Scraper / LMS Agent Scraper

Un scraper automatizado para extraer tareas pendientes del portal de Unisimon Aula Pregrado.

**Versi√≥n 2 (LMS Agent Scraper):** Framework generalizado con LangGraph, perfiles YAML, MCP y soporte para m√∫ltiples portales LMS. Ver secci√≥n "Uso LMS Agent Scraper (v2)" m√°s abajo.

## Tecnolog√≠as, est√°ndares y protocolos

Tabla por categor√≠a de lo usado en la implementaci√≥n del repo:

<table>
<thead>
<tr>
<th>Categor√≠a</th>
<th>Tecnolog√≠a / Est√°ndar / Protocolo</th>
<th>Uso en el proyecto</th>
</tr>
</thead>
<tbody>
<tr>
<td style="background-color:#e3f2fd;">Lenguaje y runtime</td>
<td style="background-color:#e3f2fd;">Python 3.10+</td>
<td style="background-color:#e3f2fd;">Lenguaje principal; tipado y sintaxis modernos.</td>
</tr>
<tr>
<td style="background-color:#e8f5e9;">Orquestaci√≥n</td>
<td style="background-color:#e8f5e9;">LangGraph</td>
<td style="background-color:#e8f5e9;">Grafo de estados: auth ‚Üí discovery ‚Üí extracci√≥n ‚Üí reporte.</td>
</tr>
<tr>
<td style="background-color:#e8f5e9;">Orquestaci√≥n</td>
<td style="background-color:#e8f5e9;">LangChain</td>
<td style="background-color:#e8f5e9;">Prompts (ChatPromptTemplate), mensajes (HumanMessage), integraci√≥n con LLMs.</td>
</tr>
<tr>
<td style="background-color:#fff3e0;">Automatizaci√≥n y scraping</td>
<td style="background-color:#fff3e0;">Playwright</td>
<td style="background-color:#fff3e0;">Navegador headless: login, ‚ÄúMis cursos‚Äù, discovery y captura de HTML.</td>
</tr>
<tr>
<td style="background-color:#fff3e0;">Automatizaci√≥n y scraping</td>
<td style="background-color:#fff3e0;">BeautifulSoup4</td>
<td style="background-color:#fff3e0;">Parseo HTML: tarjetas de curso, assignments, fechas.</td>
</tr>
<tr>
<td style="background-color:#fff3e0;">Automatizaci√≥n y scraping</td>
<td style="background-color:#fff3e0;">lxml</td>
<td style="background-color:#fff3e0;">Parser r√°pido para BeautifulSoup.</td>
</tr>
<tr>
<td style="background-color:#fff3e0;">Automatizaci√≥n y scraping</td>
<td style="background-color:#fff3e0;">requests</td>
<td style="background-color:#fff3e0;">HTTP para p√°ginas de curso (sesi√≥n autenticada).</td>
</tr>
<tr>
<td style="background-color:#f3e5f5;">LLM e IA</td>
<td style="background-color:#f3e5f5;">Ollama</td>
<td style="background-color:#f3e5f5;">Modelos locales para extracci√≥n de cursos y clasificaci√≥n de p√°ginas.</td>
</tr>
<tr>
<td style="background-color:#f3e5f5;">LLM e IA</td>
<td style="background-color:#f3e5f5;">langchain-ollama</td>
<td style="background-color:#f3e5f5;">Cliente ChatOllama e integraci√≥n con LangChain.</td>
</tr>
<tr>
<td style="background-color:#e0f2f1;">Configuraci√≥n</td>
<td style="background-color:#e0f2f1;">Pydantic / pydantic-settings</td>
<td style="background-color:#e0f2f1;">Modelos de configuraci√≥n y validaci√≥n desde .env (portal, scraper, Ollama).</td>
</tr>
<tr>
<td style="background-color:#e0f2f1;">Configuraci√≥n</td>
<td style="background-color:#e0f2f1;">python-dotenv</td>
<td style="background-color:#e0f2f1;">Carga de variables de entorno desde .env.</td>
</tr>
<tr>
<td style="background-color:#e0f2f1;">Configuraci√≥n</td>
<td style="background-color:#e0f2f1;">PyYAML</td>
<td style="background-color:#e0f2f1;">Perfiles por portal (selectores, auth, course_discovery) en profiles/.</td>
</tr>
<tr>
<td style="background-color:#e0f2f1;">Configuraci√≥n</td>
<td style="background-color:#e0f2f1;">Typer</td>
<td style="background-color:#e0f2f1;">CLI: run, profiles list/validate.</td>
</tr>
<tr>
<td style="background-color:#e0f2f1;">Configuraci√≥n</td>
<td style="background-color:#e0f2f1;">Rich</td>
<td style="background-color:#e0f2f1;">Salida enriquecida en terminal (opcional en CLI).</td>
</tr>
<tr>
<td style="background-color:#ffebee;">Protocolos</td>
<td style="background-color:#ffebee;">MCP (Model Context Protocol)</td>
<td style="background-color:#ffebee;">Servidor FastMCP v√≠a stdio; herramientas get_courses, get_pending_assignments, etc.</td>
</tr>
<tr>
<td style="background-color:#ffebee;">Protocolos</td>
<td style="background-color:#ffebee;">HTTP/HTTPS</td>
<td style="background-color:#ffebee;">Comunicaci√≥n con el portal LMS y con Ollama.</td>
</tr>
<tr>
<td style="background-color:#ffebee;">Protocolos</td>
<td style="background-color:#ffebee;">stdio</td>
<td style="background-color:#ffebee;">Transporte del servidor MCP para Cursor / Claude Desktop.</td>
</tr>
<tr>
<td style="background-color:#fafafa;">Formatos</td>
<td style="background-color:#fafafa;">YAML</td>
<td style="background-color:#fafafa;">Perfiles de portal y front matter en skills (SKILL.md).</td>
</tr>
<tr>
<td style="background-color:#fafafa;">Formatos</td>
<td style="background-color:#fafafa;">Markdown</td>
<td style="background-color:#fafafa;">Reportes de tareas y documentaci√≥n de skills (SKILL.md).</td>
</tr>
<tr>
<td style="background-color:#fafafa;">Formatos</td>
<td style="background-color:#fafafa;">JSON</td>
<td style="background-color:#fafafa;">Respuestas estructuradas del LLM (cursos, fechas); respuestas MCP.</td>
</tr>
<tr>
<td style="background-color:#fafafa;">Formatos</td>
<td style="background-color:#fafafa;">HTML</td>
<td style="background-color:#fafafa;">P√°ginas del portal; parseo con BeautifulSoup y selectores CSS.</td>
</tr>
<tr>
<td style="background-color:#efebe9;">Est√°ndares y pr√°cticas</td>
<td style="background-color:#efebe9;">SOLID / DRY</td>
<td style="background-color:#efebe9;">Principios de dise√±o; ver docs/SOLID_AND_QUALITY.md.</td>
</tr>
<tr>
<td style="background-color:#efebe9;">Est√°ndares y pr√°cticas</td>
<td style="background-color:#efebe9;">Selectores CSS</td>
<td style="background-color:#efebe9;">Perfiles YAML (tarjetas, nombre, enlace, ‚ÄúVer m√°s‚Äù).</td>
</tr>
<tr>
<td style="background-color:#e1f5fe;">Desarrollo</td>
<td style="background-color:#e1f5fe;">pytest / pytest-asyncio</td>
<td style="background-color:#e1f5fe;">Tests en tests/.</td>
</tr>
<tr>
<td style="background-color:#e1f5fe;">Desarrollo</td>
<td style="background-color:#e1f5fe;">ruff</td>
<td style="background-color:#e1f5fe;">Linter y formateo (py310, line-length 100).</td>
</tr>
<tr>
<td style="background-color:#e1f5fe;">Desarrollo</td>
<td style="background-color:#e1f5fe;">setuptools / wheel</td>
<td style="background-color:#e1f5fe;">Empaquetado (pyproject.toml, pip install -e .).</td>
</tr>
<tr>
<td style="background-color:#fce4ec;">Portal objetivo</td>
<td style="background-color:#fce4ec;">Moodle (Aula Pregrado)</td>
<td style="background-color:#fce4ec;">Unisimon: aulapregrado.unisimon.edu.co; perfil moodle_unisimon.</td>
</tr>
<tr>
<td style="background-color:#fff8e1;">Legacy</td>
<td style="background-color:#fff8e1;">Selenium / webdriver-manager</td>
<td style="background-color:#fff8e1;">Scripts alternativos scraper_selenium.py, scraper_hybrid.py.</td>
</tr>
</tbody>
</table>

## üöÄ Caracter√≠sticas

- ‚úÖ Autenticaci√≥n autom√°tica en el portal (Playwright)
- üìÖ Filtrado de tareas por per√≠odo personalizable (d√≠as adelante/atr√°s)
- üìä Generaci√≥n de reportes en formato Markdown
- üîç Modo debug para an√°lisis del portal
- üõ†Ô∏è **v2:** Workflow LangGraph (auth ‚Üí discovery ‚Üí extracci√≥n ‚Üí reporte), perfiles YAML, MCP
- üõ†Ô∏è **v2:** Detecci√≥n de cursos: BeautifulSoup (principal), LLM (Ollama) y Playwright como respaldo; detecci√≥n de presencia de tarjetas; fallback por contenido (visitar enlaces y clasificar con LLM)
- üõ†Ô∏è Scripts legacy: `scraper.py`, `scraper_selenium.py`, `scraper_hybrid.py` para uso sin el paquete v2

## üìÅ Estructura del Proyecto

```
unisimon_scraper/
‚îú‚îÄ‚îÄ scraper.py              # Script principal (legacy)
‚îú‚îÄ‚îÄ scraper_selenium.py     # Alternativa con Selenium (legacy)
‚îú‚îÄ‚îÄ scraper_hybrid.py       # H√≠brido (legacy)
‚îú‚îÄ‚îÄ config.py               # Configuraci√≥n legacy
‚îú‚îÄ‚îÄ utils.py                # Utilidades legacy
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ pyproject.toml          # Paquete instalable (v2)
‚îú‚îÄ‚îÄ .env.example            # Plantilla de variables para v2
‚îú‚îÄ‚îÄ profiles/               # Perfiles YAML por portal (v2)
‚îÇ   ‚îú‚îÄ‚îÄ moodle_unisimon.yml
‚îÇ   ‚îú‚îÄ‚îÄ moodle_default.yml
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ src/lms_agent_scraper/  # LMS Agent Scraper (v2)
‚îÇ   ‚îú‚îÄ‚îÄ cli.py              # Comandos: run, profiles list/validate
‚îÇ   ‚îú‚îÄ‚îÄ agents/             # Agentes (login, course discovery, analyzer)
‚îÇ   ‚îú‚îÄ‚îÄ graph/              # Workflow LangGraph (nodes, workflow, state)
‚îÇ   ‚îú‚îÄ‚îÄ llm/                # Cliente Ollama (extracci√≥n y clasificaci√≥n)
‚îÇ   ‚îú‚îÄ‚îÄ tools/              # browser_tools, extraction_tools, report_tools
‚îÇ   ‚îú‚îÄ‚îÄ core/               # date_parser, profile_loader, skill_loader
‚îÇ   ‚îú‚îÄ‚îÄ skills/             # Prompts LLM en SKILL.md (date-interpreter, course-extractor, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ mcp/                # Servidor MCP
‚îú‚îÄ‚îÄ validate_skills.py      # Valida que los skills (SKILL.md) carguen correctamente
‚îú‚îÄ‚îÄ .agents/skills/        # Skills de skills.sh (agent-browser, pdf, webapp-testing, etc.)
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ AGENT_SKILLS.md
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE_VERIFICATION.md
‚îÇ   ‚îî‚îÄ‚îÄ SOLID_AND_QUALITY.md
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ reports/                # Reportes Markdown generados
```

## ‚öôÔ∏è Configuraci√≥n

### 1. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 2. Configurar Credenciales

Edita `config.py` y actualiza las siguientes constantes:

```python
# Credenciales de acceso
USERNAME = 'tu_usuario'
PASSWORD = 'tu_contrase√±a'

# Per√≠odo de consulta (en d√≠as)
DAYS_AHEAD = 21  # Cambia este valor para modificar el per√≠odo
```

### 3. Personalizar Configuraci√≥n

Puedes modificar estas constantes en `config.py`:

- `DAYS_AHEAD`: N√∫mero de d√≠as hacia adelante para buscar tareas (por defecto: 21 d√≠as)
- `REQUEST_TIMEOUT`: Timeout para las peticiones HTTP (por defecto: 30 segundos)
- `DEBUG_MODE`: Activar/desactivar mensajes de debug
- `SAVE_HTML_DEBUG`: Guardar p√°ginas HTML para an√°lisis

## üéØ Uso

### Ejecuci√≥n B√°sica

```bash
python scraper.py
```

### Salida

El script generar√°:

1. **Reporte Markdown**: `reports/assignments_report_YYYYMMDD_HHMMSS.md`
2. **Archivos de Debug** (si est√° habilitado): `debug_html/`
3. **Mensajes en consola** con el progreso y resultados

## üìä Formato del Reporte

El reporte incluye:

- üìÖ Fecha de generaci√≥n y per√≠odo consultado
- üìñ Tareas agrupadas por curso
- ‚è∞ Fechas de entrega con indicadores de urgencia
- üìù Descripciones y requisitos de cada tarea
- üî¢ Conteo total de tareas encontradas

## üîß Soluci√≥n de Problemas

### Error de Autenticaci√≥n

Si el login falla:

1. Verifica las credenciales en `config.py`
2. Comprueba que la URL del portal sea correcta
3. Revisa los archivos HTML de debug en `debug_html/`

### No se Encuentran Tareas

Si no se encuentran tareas:

1. **Portal con JavaScript**: El portal podr√≠a usar JavaScript para cargar contenido din√°micamente
2. **Estructura cambiada**: El portal podr√≠a haber cambiado su estructura HTML
3. **Sin tareas**: Realmente no hay tareas en el per√≠odo consultado
4. **v2 / Unisimon**: Si usas el scraper v2 con Unisimon Aula Pregrado, pon `PORTAL_PROFILE=moodle_unisimon` en `.env`. Con `moodle_default` puede que no se detecten las tarjetas de curso. Para depurar: `SCRAPER_DEBUG_MODE=true` y revisar `debug_html/courses_page.html`.

### Migraci√≥n a Selenium

Si BeautifulSoup no es suficiente (contenido JavaScript), sigue estos pasos:

#### 1. Instalar Selenium

```bash
pip install selenium
```

#### 2. Instalar Driver del Navegador

**Para Chrome:**
```bash
# Descargar ChromeDriver desde: https://chromedriver.chromium.org/
# O usar webdriver-manager:
pip install webdriver-manager
```

#### 3. Crear `scraper_selenium.py`

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service

class UnisimonSeleniumScraper:
    def __init__(self):
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service)
        self.driver.implicitly_wait(10)
    
    def login(self):
        self.driver.get(LOGIN_URL)
        # Implementar login con Selenium
        # ...
    
    def get_assignments(self):
        # Implementar extracci√≥n con Selenium
        # ...
```

## üìù Notas Importantes

- ‚ö†Ô∏è **Uso Responsable**: Este scraper es para uso personal √∫nicamente
- üîí **Seguridad**: En el flujo legacy las credenciales est√°n en `config.py`; en v2 se usan variables de entorno (`.env`, no versionado; ver `.env.example`). Entorno virtual: `ENV_README.md`.
- üìä **Limitaciones**: Depende de la estructura HTML del portal
- üîÑ **Mantenimiento**: Puede requerir actualizaciones si el portal cambia

## üÜò Soporte

Si encuentras problemas:

1. Revisa los archivos de debug en `debug_html/`
2. Verifica que las dependencias est√©n instaladas correctamente
3. Considera usar Selenium para portales con JavaScript
4. Revisa la estructura HTML del portal para actualizar los selectores

---

## LMS Agent Scraper (v2)

### Requisitos

- Python 3.10+
- Playwright: `pip install playwright && playwright install chromium`
- Variables de entorno en `.env` (copiar desde `.env.example`)

### Configuraci√≥n

1. Copiar `.env.example` a `.env` y configurar:
   - `PORTAL_PROFILE` (ej: `moodle_unisimon` o `moodle_default`). **Para Unisimon Aula Pregrado (aulapregrado.unisimon.edu.co) usar `moodle_unisimon`.**
   - `PORTAL_BASE_URL`, `PORTAL_USERNAME`, `PORTAL_PASSWORD`
   - Opcional: `SCRAPER_DAYS_AHEAD`, `SCRAPER_DAYS_BEHIND`, `SCRAPER_MAX_COURSES`, `SCRAPER_OUTPUT_DIR`, `SCRAPER_DEBUG_MODE` (guardar HTML en `debug_html/` y m√°s logs)
   - Opcional (Ollama): `OLLAMA_BASE_URL`, `OLLAMA_MODEL_NAME`, `OLLAMA_TEMPERATURE`, `OLLAMA_NUM_CTX`, `OLLAMA_NUM_PREDICT` ‚Äî usado para extraer la lista de cursos desde el HTML, clasificar p√°ginas como ‚Äúcurso‚Äù en el discovery por contenido y (en el futuro) sugerir selectores. Requiere Ollama en ejecuci√≥n y un modelo (p. ej. `ollama run glm-4.7-flash`). Ver [ollama.com/library/glm-4.7-flash](https://ollama.com/library/glm-4.7-flash). Si no est√° disponible, la extracci√≥n se hace con BeautifulSoup y Playwright.

2. Perfiles YAML en `profiles/` definen selectores, auth y opciones por portal (Moodle, Canvas, etc.). El perfil `moodle_unisimon` est√° ajustado para Unisimon Aula Pregrado e incluye `course_discovery` para el fallback por contenido.

### Detecci√≥n de cursos (v2)

En la p√°gina "Mis cursos" del portal, la lista de cursos se obtiene en este orden:

1. **Enlaces por segmento de URL** ‚Äî m√©todo principal: se buscan todos los enlaces cuya URL tenga en **alg√∫n segmento del path** una de las palabras clave configuradas (p. ej. `course`, `courses`, `cursos`). La comparaci√≥n es **case-insensitive**. No depende de clases ni selectores CSS. Se configura con `course_link_segments` (lista) o `course_link_segment` (singular) en el perfil; si no se define, se usa por defecto `["course", "courses", "cursos"]`.
2. **BeautifulSoup (HTML)** ‚Äî respaldo: se parsea el HTML con los selectores del perfil (tarjetas, nombre, enlace; ver esquema del bloque `courses` m√°s abajo).
3. **LLM (Ollama)** ‚Äî respaldo: si BeautifulSoup no devuelve cursos y Ollama est√° disponible, se env√≠a un fragmento del HTML al modelo configurado para que devuelva un JSON con la lista de cursos (nombre y URL).
4. **Playwright** ‚Äî respaldo: primero se prueban todos los enlaces de la p√°gina filtrados por las mismas palabras de segmento; si no hay resultados, se usan los locators del perfil (`courses.selectors`) dentro del contenedor opcional (`courses.container`).
5. **Discovery por contenido** ‚Äî fallback opcional (perfil `course_discovery.fallback_when_empty: true`): si sigue habiendo 0 cursos, se extraen enlaces candidatos, se visitan y el LLM clasifica si son p√°ginas de curso. Configurable con `max_candidates` y `candidate_patterns`.

Antes de extraer, se detecta la presencia de tarjetas de curso (`detect_courses_presence`) y, si el perfil lo indica, se puede expandir "Ver m√°s" / paginaci√≥n (`more_navigation`) antes de capturar el HTML.

#### Esquema del bloque `courses` en el perfil

Todos los campos son **opcionales**. Si no se definen, se usan valores por defecto compatibles con Moodle (block_myoverview / tarjetas). As√≠ puedes reutilizar el mismo c√≥digo en otros portales (Canvas, Blackboard, Moodle custom) solo configurando el perfil.

<table>
<colgroup><col style="width: 38%"><col style="width: 42%"><col style="width: 20%"></colgroup>
<thead>
<tr><th>Campo</th><th>Descripci√≥n</th><th>Por defecto (Moodle)</th></tr>
</thead>
<tbody>
<tr><td><code>course_link_segments</code></td><td>Lista de palabras que identifican un enlace a curso si aparecen en alg√∫n segmento del path de la URL (case-insensitive). Ej.: <code>["course", "courses", "cursos"]</code>.</td><td><code>["course", "courses", "cursos"]</code></td></tr>
<tr><td><code>course_link_segment</code></td><td>Alternativa en singular (una sola palabra); se convierte en lista de un elemento.</td><td>‚Äî</td></tr>
<tr><td><code>container</code></td><td>Contenedor opcional para acotar la b√∫squeda (Playwright).</td><td><code>[data-region='courses-view']</code></td></tr>
<tr><td><code>selectors</code></td><td>Lista de selectores CSS para enlaces a curso (Playwright).</td><td><code>a[href*='course/view.php']</code></td></tr>
<tr><td><code>card_selectors</code></td><td>Selectores que identifican una tarjeta/√≠tem de curso (BeautifulSoup y detecci√≥n de presencia).</td><td><code>[data-region='course-content']</code>, <code>div.card.course-card</code></td></tr>
<tr><td><code>name_selectors</code></td><td>Dentro de cada tarjeta, selectores para el nombre del curso (texto o <code>title</code>).</td><td><code>a.coursename</code>, <code>span.multiline</code>, <code>[title]</code></td></tr>
<tr><td><code>link_selector</code></td><td>Dentro de cada tarjeta, selector del enlace al curso.</td><td>Enlace cuyo <code>href</code> cumple <code>link_href_pattern</code></td></tr>
<tr><td><code>link_href_pattern</code></td><td>Patr√≥n que debe aparecer en el <code>href</code> (ej. <code>course/view</code>, <code>/course/</code>).</td><td><code>course/view</code></td></tr>
<tr><td><code>fallback_containers</code></td><td>Si no hay tarjetas, buscar enlaces dentro de estos contenedores.</td><td><code>[data-region='courses-view']</code>, <code>.card-deck</code>, <code>.course-box</code></td></tr>
<tr><td><code>more_navigation</code></td><td>Objeto opcional para "Ver m√°s" / paginaci√≥n antes de extraer.</td><td>No se expande</td></tr>
<tr><td><code>more_navigation.selectors</code></td><td>Lista de selectores (ej. <code>button:has-text('Ver m√°s')</code>, <code>a:has-text('Siguiente')</code>).</td><td>‚Äî</td></tr>
<tr><td><code>more_navigation.expand_before_extract</code></td><td>Si <code>true</code>, hacer click en los controles antes de capturar HTML.</td><td><code>false</code></td></tr>
<tr><td><code>more_navigation.max_clicks</code></td><td>N√∫mero m√°ximo de clicks en "Ver m√°s" / siguiente.</td><td><code>0</code></td></tr>
</tbody>
</table>

### Uso

```bash
# Instalar el paquete en modo editable (desde la ra√≠z del repo)
pip install -e .

# Ejecutar scraper (perfil desde .env, ej. moodle_default)
python -m lms_agent_scraper.cli run

# Con perfil espec√≠fico (recomendado para Unisimon Aula Pregrado)
python -m lms_agent_scraper.cli run --profile moodle_unisimon

# Modo debug: SCRAPER_DEBUG_MODE=true en .env para guardar HTML en debug_html/ y m√°s logs

# Listar y validar perfiles
python -m lms_agent_scraper.cli profiles list
python -m lms_agent_scraper.cli profiles validate moodle_unisimon

# Tests (desde la ra√≠z del repo)
pytest tests/ -v
```

### MCP Server (Cursor / Claude Desktop)

En la configuraci√≥n MCP del cliente:

```json
{
  "mcpServers": {
    "lms-scraper": {
      "command": "python",
      "args": ["-m", "lms_agent_scraper.mcp.server"],
      "env": {
        "PORTAL_PROFILE": "moodle_unisimon",
        "PORTAL_BASE_URL": "${env:PORTAL_BASE_URL}",
        "PORTAL_USERNAME": "${env:PORTAL_USERNAME}",
        "PORTAL_PASSWORD": "${env:PORTAL_PASSWORD}"
      }
    }
  }
}
```

Herramientas expuestas: `get_pending_assignments`, `get_submitted_assignments`, `get_courses`, `generate_report`, `check_deadlines`, `list_profiles`. El servidor env√≠a `instructions` al cliente indicando que se trata del portal LMS de la **Universidad Sim√≥n Bol√≠var (Unisimon), Aula Pregrado**, para que el agente tenga ese contexto.

### Desarrollo con Cursor

Este proyecto se desarrolla con Cursor. Se usan **reglas globales** en `~/.cursor/rules/` (aplican a todos los proyectos):

- **SOLID y calidad**: `solid-and-quality.mdc` ‚Äî principios SOLID, DRY y buenas pr√°cticas. Copia en el repo: [docs/SOLID_AND_QUALITY.md](docs/SOLID_AND_QUALITY.md). Verificaci√≥n de cumplimiento: [docs/ARCHITECTURE_VERIFICATION.md](docs/ARCHITECTURE_VERIFICATION.md).
- **Idioma**: `comments-spanish-code-english.mdc` ‚Äî comentarios y docstrings en espa√±ol; nombres de c√≥digo en ingl√©s.

**MCPs opcionales** (instalados en `C:\MCPs\` y configurados en `~/.cursor/mcp.json`):

| MCP | Descripci√≥n |
|-----|-------------|
| **pdf-reader** | Lee texto de archivos PDF. |
| **char-counter** | Cuenta caracteres, palabras y l√≠neas en texto o archivo. |
| **unused-vars** | Analiza c√≥digo Python y detecta variables/funciones no usadas y variables de entorno referenciadas; opcionalmente compara con un `.env`. |

Para analizar este repo con unused-vars (y opcionalmente el `.env`), el agente puede llamar a la herramienta `analyze_unused` con `path` al directorio del proyecto y `env_file` al `.env`.

### Agent Skills (skills.sh)

Para mejorar el comportamiento de agentes al trabajar con este repo, instala skills desde [skills.sh](https://skills.sh/). Se instalan en **`.agents/skills/`** y **Cursor (y otros agentes compatibles) los usan autom√°ticamente** al trabajar en este repositorio. En `docs/AGENT_SKILLS.md` encontrar√°s la lista por prioridad, la tabla labores‚Äìskills y la integraci√≥n con los agentes.

**Esenciales:** `vercel-labs/agent-browser`, `anthropics/skills` (incluye pdf y webapp-testing). **Recomendados:** `browser-use/browser-use`, `obra/superpowers`. **Opcionales:** `wshobson/agents`.

```bash
npx skills add vercel-labs/agent-browser --yes
npx skills add anthropics/skills --yes
npx skills add browser-use/browser-use --yes
npx skills add obra/superpowers --yes
```

Ver `docs/AGENT_SKILLS.md` para todos los comandos y `npx skills list` para listar los instalados.

**Skills en tiempo de ejecuci√≥n (prompts del LLM):** Los prompts que usa Ollama est√°n en `src/lms_agent_scraper/skills/` (archivos SKILL.md por tarea: extracci√≥n de cursos, fechas, selectores, etc.). Puedes editarlos sin tocar c√≥digo. Para validar que carguen bien: `python validate_skills.py`. Detalle en `docs/AGENT_SKILLS.md` (secci√≥n "Skills en tiempo de ejecuci√≥n").

---

## üìÑ Licencia

Este proyecto es para uso educativo y personal √∫nicamente.
