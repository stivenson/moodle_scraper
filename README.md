# Unisimon Portal Scraper / LMS Agent Scraper

Un scraper automatizado para extraer tareas pendientes del portal de Unisimon Aula Pregrado.

**VersiÃ³n 2 (LMS Agent Scraper):** Framework generalizado con LangGraph, perfiles YAML, MCP y soporte para mÃºltiples portales LMS. Ver secciÃ³n "Uso LMS Agent Scraper (v2)" mÃ¡s abajo.

## ğŸš€ CaracterÃ­sticas

- âœ… AutenticaciÃ³n automÃ¡tica en el portal (Playwright)
- ğŸ“… Filtrado de tareas por perÃ­odo personalizable (dÃ­as adelante/atrÃ¡s)
- ğŸ“Š GeneraciÃ³n de reportes en formato Markdown
- ğŸ” Modo debug para anÃ¡lisis del portal
- ğŸ› ï¸ **v2:** Workflow LangGraph (auth â†’ discovery â†’ extracciÃ³n â†’ reporte), perfiles YAML, MCP
- ğŸ› ï¸ **v2:** DetecciÃ³n de cursos: BeautifulSoup (principal), LLM (Ollama) y Playwright como respaldo; detecciÃ³n de presencia de tarjetas; fallback por contenido (visitar enlaces y clasificar con LLM)
- ğŸ› ï¸ Scripts legacy: `scraper.py`, `scraper_selenium.py`, `scraper_hybrid.py` para uso sin el paquete v2

## ğŸ“ Estructura del Proyecto

```
unisimon_scraper/
â”œâ”€â”€ scraper.py              # Script principal (legacy)
â”œâ”€â”€ scraper_selenium.py     # Alternativa con Selenium (legacy)
â”œâ”€â”€ scraper_hybrid.py       # HÃ­brido (legacy)
â”œâ”€â”€ config.py               # ConfiguraciÃ³n legacy
â”œâ”€â”€ utils.py                # Utilidades legacy
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml          # Paquete instalable (v2)
â”œâ”€â”€ .env.example            # Plantilla de variables para v2
â”œâ”€â”€ profiles/               # Perfiles YAML por portal (v2)
â”‚   â”œâ”€â”€ moodle_unisimon.yml
â”‚   â”œâ”€â”€ moodle_default.yml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/lms_agent_scraper/  # LMS Agent Scraper (v2)
â”‚   â”œâ”€â”€ cli.py              # Comandos: run, profiles list/validate
â”‚   â”œâ”€â”€ agents/             # Agentes (login, course discovery, analyzer)
â”‚   â”œâ”€â”€ graph/              # Workflow LangGraph (nodes, workflow, state)
â”‚   â”œâ”€â”€ llm/                # Cliente Ollama (extracciÃ³n y clasificaciÃ³n)
â”‚   â”œâ”€â”€ tools/              # browser_tools, extraction_tools, report_tools
â”‚   â”œâ”€â”€ core/               # date_parser, profile_loader, skill_loader
â”‚   â”œâ”€â”€ skills/             # Prompts LLM en SKILL.md (date-interpreter, course-extractor, etc.)
â”‚   â””â”€â”€ mcp/                # Servidor MCP
â”œâ”€â”€ validate_skills.py      # Valida que los skills (SKILL.md) carguen correctamente
â”œâ”€â”€ .agents/skills/        # Skills de skills.sh (agent-browser, pdf, webapp-testing, etc.)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AGENT_SKILLS.md
â”‚   â”œâ”€â”€ ARCHITECTURE_VERIFICATION.md
â”‚   â””â”€â”€ SOLID_AND_QUALITY.md
â”œâ”€â”€ tests/
â””â”€â”€ reports/                # Reportes Markdown generados
```

## âš™ï¸ ConfiguraciÃ³n

### 1. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 2. Configurar Credenciales

Edita `config.py` y actualiza las siguientes constantes:

```python
# Credenciales de acceso
USERNAME = 'tu_usuario'
PASSWORD = 'tu_contraseÃ±a'

# PerÃ­odo de consulta (en dÃ­as)
DAYS_AHEAD = 21  # Cambia este valor para modificar el perÃ­odo
```

### 3. Personalizar ConfiguraciÃ³n

Puedes modificar estas constantes en `config.py`:

- `DAYS_AHEAD`: NÃºmero de dÃ­as hacia adelante para buscar tareas (por defecto: 21 dÃ­as)
- `REQUEST_TIMEOUT`: Timeout para las peticiones HTTP (por defecto: 30 segundos)
- `DEBUG_MODE`: Activar/desactivar mensajes de debug
- `SAVE_HTML_DEBUG`: Guardar pÃ¡ginas HTML para anÃ¡lisis

## ğŸ¯ Uso

### EjecuciÃ³n BÃ¡sica

```bash
python scraper.py
```

### Salida

El script generarÃ¡:

1. **Reporte Markdown**: `reports/assignments_report_YYYYMMDD_HHMMSS.md`
2. **Archivos de Debug** (si estÃ¡ habilitado): `debug_html/`
3. **Mensajes en consola** con el progreso y resultados

## ğŸ“Š Formato del Reporte

El reporte incluye:

- ğŸ“… Fecha de generaciÃ³n y perÃ­odo consultado
- ğŸ“– Tareas agrupadas por curso
- â° Fechas de entrega con indicadores de urgencia
- ğŸ“ Descripciones y requisitos de cada tarea
- ğŸ”¢ Conteo total de tareas encontradas

## ğŸ”§ SoluciÃ³n de Problemas

### Error de AutenticaciÃ³n

Si el login falla:

1. Verifica las credenciales en `config.py`
2. Comprueba que la URL del portal sea correcta
3. Revisa los archivos HTML de debug en `debug_html/`

### No se Encuentran Tareas

Si no se encuentran tareas:

1. **Portal con JavaScript**: El portal podrÃ­a usar JavaScript para cargar contenido dinÃ¡micamente
2. **Estructura cambiada**: El portal podrÃ­a haber cambiado su estructura HTML
3. **Sin tareas**: Realmente no hay tareas en el perÃ­odo consultado
4. **v2 / Unisimon**: Si usas el scraper v2 con Unisimon Aula Pregrado, pon `PORTAL_PROFILE=moodle_unisimon` en `.env`. Con `moodle_default` puede que no se detecten las tarjetas de curso. Para depurar: `SCRAPER_DEBUG_MODE=true` y revisar `debug_html/courses_page.html`.

### MigraciÃ³n a Selenium

Si BeautifulSoup no es suficiente (contenido JavaScript), sigue estos pasos:

#### 1. Instalar Selenium

```bash
pip install selenium
```

#### 2. Instalar Driver del Navegador

**Para Chrome:**
```bash
# Descargar ChromeDriver desde: https://chromedriver.chromium.org/
# O usar webdriver-manager:
pip install webdriver-manager
```

#### 3. Crear `scraper_selenium.py`

```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service

class UnisimonSeleniumScraper:
    def __init__(self):
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service)
        self.driver.implicitly_wait(10)
    
    def login(self):
        self.driver.get(LOGIN_URL)
        # Implementar login con Selenium
        # ...
    
    def get_assignments(self):
        # Implementar extracciÃ³n con Selenium
        # ...
```

## ğŸ“ Notas Importantes

- âš ï¸ **Uso Responsable**: Este scraper es para uso personal Ãºnicamente
- ğŸ”’ **Seguridad**: En el flujo legacy las credenciales estÃ¡n en `config.py`; en v2 se usan variables de entorno (`.env`, no versionado; ver `.env.example`). Entorno virtual: `ENV_README.md`.
- ğŸ“Š **Limitaciones**: Depende de la estructura HTML del portal
- ğŸ”„ **Mantenimiento**: Puede requerir actualizaciones si el portal cambia

## ğŸ†˜ Soporte

Si encuentras problemas:

1. Revisa los archivos de debug en `debug_html/`
2. Verifica que las dependencias estÃ©n instaladas correctamente
3. Considera usar Selenium para portales con JavaScript
4. Revisa la estructura HTML del portal para actualizar los selectores

---

## LMS Agent Scraper (v2)

### Requisitos

- Python 3.10+
- Playwright: `pip install playwright && playwright install chromium`
- Variables de entorno en `.env` (copiar desde `.env.example`)

### ConfiguraciÃ³n

1. Copiar `.env.example` a `.env` y configurar:
   - `PORTAL_PROFILE` (ej: `moodle_unisimon` o `moodle_default`). **Para Unisimon Aula Pregrado (aulapregrado.unisimon.edu.co) usar `moodle_unisimon`.**
   - `PORTAL_BASE_URL`, `PORTAL_USERNAME`, `PORTAL_PASSWORD`
   - Opcional: `SCRAPER_DAYS_AHEAD`, `SCRAPER_DAYS_BEHIND`, `SCRAPER_MAX_COURSES`, `SCRAPER_OUTPUT_DIR`, `SCRAPER_DEBUG_MODE` (guardar HTML en `debug_html/` y mÃ¡s logs)
   - Opcional (Ollama): `OLLAMA_BASE_URL`, `OLLAMA_MODEL_NAME`, `OLLAMA_TEMPERATURE`, `OLLAMA_NUM_CTX`, `OLLAMA_NUM_PREDICT` â€” usado para extraer la lista de cursos desde el HTML, clasificar pÃ¡ginas como â€œcursoâ€ en el discovery por contenido y (en el futuro) sugerir selectores. Requiere Ollama en ejecuciÃ³n y un modelo (p. ej. `ollama run glm-4.7-flash`). Ver [ollama.com/library/glm-4.7-flash](https://ollama.com/library/glm-4.7-flash). Si no estÃ¡ disponible, la extracciÃ³n se hace con BeautifulSoup y Playwright.

2. Perfiles YAML en `profiles/` definen selectores, auth y opciones por portal (Moodle, Canvas, etc.). El perfil `moodle_unisimon` estÃ¡ ajustado para Unisimon Aula Pregrado e incluye `course_discovery` para el fallback por contenido.

### DetecciÃ³n de cursos (v2)

En la pÃ¡gina "Mis cursos" del portal, la lista de cursos se obtiene en este orden:

1. **Enlaces por segmento de URL** â€” mÃ©todo principal: se buscan todos los enlaces cuya URL tenga en **algÃºn segmento del path** una de las palabras clave configuradas (p. ej. `course`, `courses`, `cursos`). La comparaciÃ³n es **case-insensitive**. No depende de clases ni selectores CSS. Se configura con `course_link_segments` (lista) o `course_link_segment` (singular) en el perfil; si no se define, se usa por defecto `["course", "courses", "cursos"]`.
2. **BeautifulSoup (HTML)** â€” respaldo: se parsea el HTML con los selectores del perfil (tarjetas, nombre, enlace; ver esquema del bloque `courses` mÃ¡s abajo).
3. **LLM (Ollama)** â€” respaldo: si BeautifulSoup no devuelve cursos y Ollama estÃ¡ disponible, se envÃ­a un fragmento del HTML al modelo configurado para que devuelva un JSON con la lista de cursos (nombre y URL).
4. **Playwright** â€” respaldo: primero se prueban todos los enlaces de la pÃ¡gina filtrados por las mismas palabras de segmento; si no hay resultados, se usan los locators del perfil (`courses.selectors`) dentro del contenedor opcional (`courses.container`).
5. **Discovery por contenido** â€” fallback opcional (perfil `course_discovery.fallback_when_empty: true`): si sigue habiendo 0 cursos, se extraen enlaces candidatos, se visitan y el LLM clasifica si son pÃ¡ginas de curso. Configurable con `max_candidates` y `candidate_patterns`.

Antes de extraer, se detecta la presencia de tarjetas de curso (`detect_courses_presence`) y, si el perfil lo indica, se puede expandir "Ver mÃ¡s" / paginaciÃ³n (`more_navigation`) antes de capturar el HTML.

#### Esquema del bloque `courses` en el perfil

Todos los campos son **opcionales**. Si no se definen, se usan valores por defecto compatibles con Moodle (block_myoverview / tarjetas). AsÃ­ puedes reutilizar el mismo cÃ³digo en otros portales (Canvas, Blackboard, Moodle custom) solo configurando el perfil.

| Campo | DescripciÃ³n | Por defecto (Moodle) |
|-------|-------------|----------------------|
| `course_link_segments` | Lista de palabras que identifican un enlace a curso si aparecen en algÃºn segmento del path de la URL (case-insensitive). Ej.: `["course", "courses", "cursos"]`. | `["course", "courses", "cursos"]` |
| `course_link_segment` | Alternativa en singular (una sola palabra); se convierte en lista de un elemento. | â€” |
| `container` | Contenedor opcional para acotar la bÃºsqueda (Playwright). | `[data-region='courses-view']` |
| `selectors` | Lista de selectores CSS para enlaces a curso (Playwright). | `a[href*='course/view.php']` |
| `card_selectors` | Selectores que identifican una tarjeta/Ã­tem de curso (BeautifulSoup y detecciÃ³n de presencia). | `[data-region='course-content']`, `div.card.course-card` |
| `name_selectors` | Dentro de cada tarjeta, selectores para el nombre del curso (texto o `title`). | `a.coursename`, `span.multiline`, `[title]` |
| `link_selector` | Dentro de cada tarjeta, selector del enlace al curso. | Enlace cuyo `href` cumple `link_href_pattern` |
| `link_href_pattern` | PatrÃ³n que debe aparecer en el `href` (ej. `course/view`, `/course/`). | `course/view` |
| `fallback_containers` | Si no hay tarjetas, buscar enlaces dentro de estos contenedores. | `[data-region='courses-view']`, `.card-deck`, `.course-box` |
| `more_navigation` | Objeto opcional para "Ver mÃ¡s" / paginaciÃ³n antes de extraer. | No se expande |
| `more_navigation.selectors` | Lista de selectores (ej. `button:has-text('Ver mÃ¡s')`, `a:has-text('Siguiente')`). | â€” |
| `more_navigation.expand_before_extract` | Si `true`, hacer click en los controles antes de capturar HTML. | `false` |
| `more_navigation.max_clicks` | NÃºmero mÃ¡ximo de clicks en "Ver mÃ¡s" / siguiente. | `0` |

### Uso

```bash
# Instalar el paquete en modo editable (desde la raÃ­z del repo)
pip install -e .

# Ejecutar scraper (perfil desde .env, ej. moodle_default)
python -m lms_agent_scraper.cli run

# Con perfil especÃ­fico (recomendado para Unisimon Aula Pregrado)
python -m lms_agent_scraper.cli run --profile moodle_unisimon

# Modo debug: SCRAPER_DEBUG_MODE=true en .env para guardar HTML en debug_html/ y mÃ¡s logs

# Listar y validar perfiles
python -m lms_agent_scraper.cli profiles list
python -m lms_agent_scraper.cli profiles validate moodle_unisimon

# Tests (desde la raÃ­z del repo)
pytest tests/ -v
```

### MCP Server (Cursor / Claude Desktop)

En la configuraciÃ³n MCP del cliente:

```json
{
  "mcpServers": {
    "lms-scraper": {
      "command": "python",
      "args": ["-m", "lms_agent_scraper.mcp.server"],
      "env": {
        "PORTAL_PROFILE": "moodle_unisimon",
        "PORTAL_BASE_URL": "${env:PORTAL_BASE_URL}",
        "PORTAL_USERNAME": "${env:PORTAL_USERNAME}",
        "PORTAL_PASSWORD": "${env:PORTAL_PASSWORD}"
      }
    }
  }
}
```

Herramientas expuestas: `get_pending_assignments`, `get_submitted_assignments`, `get_courses`, `generate_report`, `check_deadlines`, `list_profiles`. El servidor envÃ­a `instructions` al cliente indicando que se trata del portal LMS de la **Universidad SimÃ³n BolÃ­var (Unisimon), Aula Pregrado**, para que el agente tenga ese contexto.

### Desarrollo con Cursor

Este proyecto se desarrolla con Cursor. Se usan **reglas globales** en `~/.cursor/rules/` (aplican a todos los proyectos):

- **SOLID y calidad**: `solid-and-quality.mdc` â€” principios SOLID, DRY y buenas prÃ¡cticas. Copia en el repo: [docs/SOLID_AND_QUALITY.md](docs/SOLID_AND_QUALITY.md). VerificaciÃ³n de cumplimiento: [docs/ARCHITECTURE_VERIFICATION.md](docs/ARCHITECTURE_VERIFICATION.md).
- **Idioma**: `comments-spanish-code-english.mdc` â€” comentarios y docstrings en espaÃ±ol; nombres de cÃ³digo en inglÃ©s.

**MCPs opcionales** (instalados en `C:\MCPs\` y configurados en `~/.cursor/mcp.json`):

| MCP | DescripciÃ³n |
|-----|-------------|
| **pdf-reader** | Lee texto de archivos PDF. |
| **char-counter** | Cuenta caracteres, palabras y lÃ­neas en texto o archivo. |
| **unused-vars** | Analiza cÃ³digo Python y detecta variables/funciones no usadas y variables de entorno referenciadas; opcionalmente compara con un `.env`. |

Para analizar este repo con unused-vars (y opcionalmente el `.env`), el agente puede llamar a la herramienta `analyze_unused` con `path` al directorio del proyecto y `env_file` al `.env`.

### Agent Skills (skills.sh)

Para mejorar el comportamiento de agentes al trabajar con este repo, instala skills desde [skills.sh](https://skills.sh/). Se instalan en **`.agents/skills/`** y **Cursor (y otros agentes compatibles) los usan automÃ¡ticamente** al trabajar en este repositorio. En `docs/AGENT_SKILLS.md` encontrarÃ¡s la lista por prioridad, la tabla laboresâ€“skills y la integraciÃ³n con los agentes.

**Esenciales:** `vercel-labs/agent-browser`, `anthropics/skills` (incluye pdf y webapp-testing). **Recomendados:** `browser-use/browser-use`, `obra/superpowers`. **Opcionales:** `wshobson/agents`.

```bash
npx skills add vercel-labs/agent-browser --yes
npx skills add anthropics/skills --yes
npx skills add browser-use/browser-use --yes
npx skills add obra/superpowers --yes
```

Ver `docs/AGENT_SKILLS.md` para todos los comandos y `npx skills list` para listar los instalados.

**Skills en tiempo de ejecuciÃ³n (prompts del LLM):** Los prompts que usa Ollama estÃ¡n en `src/lms_agent_scraper/skills/` (archivos SKILL.md por tarea: extracciÃ³n de cursos, fechas, selectores, etc.). Puedes editarlos sin tocar cÃ³digo. Para validar que carguen bien: `python validate_skills.py`. Detalle en `docs/AGENT_SKILLS.md` (secciÃ³n "Skills en tiempo de ejecuciÃ³n").

---

## ğŸ“„ Licencia

Este proyecto es para uso educativo y personal Ãºnicamente.
